# -*- coding: utf-8 -*-
"""XGBoost Binary Classifier
"""

import numpy as np
import sys
import os
import sklearn as sk
from sklearn.linear_model import LogisticRegression
import joblib
import pandas as pd

DATA_FILE = sys.argv[1]     # CSV file with features, groups, labels, and indices for which rows to use for training (use -1 or neg. for mask)
FEATURE_NAMES = sys.argv[2] # column header names (treated as strings) to use as features (data in rows, i.e. generated by np.savetxt)
CLASS_LABELS_COL = sys.argv[3]  # column header name (string) to use for class labels (i.e. y)
TRAIN_INDEX_COL = sys.argv[4]   # column header name (string) that has a 1 if that row of features should be used for training
OUTPUT_FILE = sys.argv[5]   # name for model output file (script adds the correct extension)
PRED_FILE = sys.argv[6]     # raw (not rounded) predictions (in rows, no extension will be added)
C = float(sys.argv[7])            # C parameter typical value = 0.01
L1_RATIO = float(sys.argv[8])      # L1 ratio parameter typical value = 0.93
MAX_ITER = int(sys.argv[9])      # maximum iterations (default 100)
try:
    RAND_STATE = int(sys.argv[10])
except:
    RAND_STATE = 324

# If any of PREDICT_FILE or OUTPUT_FILE are set to "na",
# then it won't be used

data = pd.read_csv(DATA_FILE)

feature_names = np.loadtxt(FEATURE_NAMES, dtype='str')
x = data[feature_names].values
# mask values that are unavailable -- indicated as negative
x = np.where(x < 0, 0, x)
y = data[CLASS_LABELS_COL].values
trainindex_col = data[TRAIN_INDEX_COL].values

trainindex = np.where(trainindex_col == 1)[0]
xtrain = x[trainindex]
ytrain = y[trainindex]

lr = LogisticRegression(penalty='elasticnet', solver='saga', C=C, l1_ratio=L1_RATIO, verbose=1, n_jobs=-1, max_iter=MAX_ITER)
lr.fit(xtrain, ytrain)

if OUTPUT_FILE.lower() != "na":
    joblib.dump(lr, OUTPUT_FILE+".joblib")

if PRED_FILE.lower() != "na":
    pred = lr.predict(x)
    np.savetxt(PRED_FILE, pred)
